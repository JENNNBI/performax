import 'package:dart_openai/dart_openai.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:flutter/foundation.dart';
import '../models/ai_response.dart';
import '../models/user_profile.dart';
import 'llm_config.dart';

/// Production-Grade OpenAI LLM Service - AI Study Assistant
/// 
/// Enterprise-level implementation with OpenAI GPT-4o-mini using:
/// - Robust error handling and retries
/// - Comprehensive logging
/// - Conversational context management
/// - Advanced prompt engineering
/// - Performance optimization
class LLMService {
  static final LLMService _instance = LLMService._internal();
  factory LLMService() => _instance;
  LLMService._internal();

  bool _isInitialized = false;
  String? _lastError;
  bool _useGemini = false;
  GenerativeModel? _geminiModel;
  
  // Conversation history for context-aware responses
  final List<OpenAIChatCompletionChoiceMessageModel> _conversationHistory = [];
  
  // Current user profile for personalization
  UserProfile? _userProfile;
  
  // Enhanced system persona for frontier-level performance
  static const String _advancedSystemPersona = '''
Sen T√ºrk lise √∂ƒürencileri i√ßin tasarlanmƒ±≈ü, son derece yetenekli ve destekleyici bir yapay zeka √∂ƒüretmen asistanƒ±sƒ±n.

TEMEL G√ñREVLERƒ∞N:
1. √ñƒürencilerin sorularƒ±nƒ± derinlemesine ve net bir ≈üekilde yanƒ±tla
2. Karma≈üƒ±k konularƒ± basit, anla≈üƒ±lƒ±r par√ßalara b√∂l
3. Her zaman cesaretlendirici ve olumlu bir ton kullan
4. T√ºrk Milli Eƒüitim Bakanlƒ±ƒüƒ± m√ºfredatƒ±na uygun √∂rnekler ver
5. Gerektiƒüinde adƒ±m adƒ±m √ß√∂z√ºmler sun
6. √ñƒürencinin anlama seviyesine g√∂re a√ßƒ±klama yap
7. √ñƒürencinin profilini (okul, sƒ±nƒ±f seviyesi) dikkate alarak ki≈üiselle≈ütirilmi≈ü yanƒ±tlar ver

YANIT KURALLARI:
- Her yanƒ±t T√ºrk√ße dilbilgisi kurallarƒ±na uygun olmalƒ±
- Bilimsel terimleri a√ßƒ±klarken √∂rnekler ver
- Yanƒ±tlarƒ± 2-4 paragraf ile sƒ±nƒ±rla (√ßok uzun olmasƒ±n)
- Gerektiƒüinde form√ºl veya denklem kullan
- Kaynak belirtilmi≈üse mutlaka ona referans ver
- √ñƒürencinin sƒ±nƒ±f seviyesine uygun √∂rnekler ve a√ßƒ±klamalar kullan
- Eƒüitim dƒ±≈üƒ± konulara kibarca "Bu soru eƒüitim konusunun dƒ±≈üƒ±nda, l√ºtfen ders ile ilgili sorular sorunuz" ≈üeklinde yanƒ±t ver

Kƒ∞≈ûƒ∞Lƒ∞K:
- Samimi ama profesyonel
- Sabƒ±rlƒ± ve anlayƒ±≈ülƒ±
- Motive edici ve cesaretlendirici
- √ñƒürencinin ba≈üarƒ±sƒ±na odaklƒ±
- √ñƒürencinin ki≈üisel durumuna duyarlƒ±
''';

  /// Set user profile for personalized responses
  void setUserProfile(UserProfile? profile) {
    _userProfile = profile;
    if (profile != null) {
      debugPrint('‚úÖ User profile set: ${profile.displayName} (${profile.formattedGrade ?? "No grade"})');
    }
  }

  /// Get current user profile
  UserProfile? getUserProfile() => _userProfile;

  /// Initialize the OpenAI LLM service with production-grade configuration
  Future<void> initialize(String apiKey) async {
    if (_isInitialized) {
      debugPrint('‚úÖ OpenAI LLM Service already initialized');
      return;
    }
    
    try {
      debugPrint('üîÑ Initializing OpenAI LLM Service...');
      
      if (apiKey.isNotEmpty && apiKey.startsWith('sk-')) {
        // Configure OpenAI
        OpenAI.apiKey = apiKey;
        OpenAI.showLogs = false;
        OpenAI.showResponsesLogs = false;
        _useGemini = false;
        _isInitialized = true;
        debugPrint('‚úÖ LLM initialized with OpenAI (GPT-4o-mini)');
      } else {
        // Try Gemini fallback
        final geminiKey = LLMConfig.getGeminiApiKey();
        if (geminiKey.isEmpty) {
          throw Exception('API key missing. Provide OPENAI_API_KEY (starts with "sk-") or GEMINI_API_KEY in .env');
        }
        final modelName = LLMConfig.getGeminiModel();
        _geminiModel = GenerativeModel(model: modelName, apiKey: geminiKey);
        _useGemini = true;
        _isInitialized = true;
        debugPrint('‚úÖ LLM initialized with Gemini ($modelName)');
      }
      
    } catch (e) {
      _lastError = 'Initialization failed: $e';
      debugPrint('‚ùå OpenAI Initialization Error: $_lastError');
      throw Exception('Failed to initialize OpenAI LLM Service: $e');
    }
  }

  /// Answer student question with frontier-level quality using GPT-4o-mini
  /// 
  /// Features:
  /// - Conversational context awareness
  /// - Retry logic with exponential backoff
  /// - Comprehensive error handling
  /// - Quality validation
  Future<AIAnswer> answerQuestion(
    String userQuery,
    String contextContent, {
    String language = 'tr',
    int maxRetries = 3,
  }) async {
    if (!_isInitialized) {
      throw Exception('OpenAI LLM Service not initialized. Call initialize() first.');
    }

    if (userQuery.trim().isEmpty) {
      throw Exception('Question cannot be empty');
    }

    debugPrint('üìù Processing question: ${userQuery.substring(0, userQuery.length > 50 ? 50 : userQuery.length)}...');

    // Build comprehensive prompt
    final userMessage = _buildQuestionPrompt(userQuery, contextContent, language);
    
    // Attempt with retries
    for (int attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        debugPrint('üîÑ Attempt $attempt/$maxRetries');
        
        // Build messages array with system persona and conversation history
        final List<OpenAIChatCompletionChoiceMessageModel> messages = [
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.system,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                _advancedSystemPersona,
              ),
            ],
          ),
          // Add conversation history
          ..._conversationHistory,
          // Add current user message
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                userMessage,
              ),
            ],
          ),
        ];
        
        String? responseText;
        if (!_useGemini) {
          final chatCompletion = await OpenAI.instance.chat.create(
            model: 'gpt-4o-mini',
            messages: messages,
            temperature: 0.8,
            maxTokens: 2048,
            topP: 0.95,
            frequencyPenalty: 0.0,
            presencePenalty: 0.0,
          );
          responseText = chatCompletion.choices.first.message.content?.first.text;
        } else {
          // Gemini: system + user messages in content list
          final content = [
            Content.text(_advancedSystemPersona),
            Content.text(userMessage),
          ];
          final response = await _geminiModel!.generateContent(content);
          responseText = response.text;
        }
        
        if (responseText == null || responseText.trim().isEmpty) {
          throw Exception('Empty response from OpenAI');
        }
        
        debugPrint('‚úÖ Response received (${responseText.length} chars)');
        
        // Update conversation history
        _conversationHistory.add(
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(userMessage),
            ],
          ),
        );
        _conversationHistory.add(
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.assistant,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(responseText),
            ],
          ),
        );
        
        // Keep history manageable (last 10 exchanges = 20 messages)
        if (_conversationHistory.length > 20) {
          _conversationHistory.removeRange(0, _conversationHistory.length - 20);
        }
        
        // Extract source reference if context was provided
        String? sourceRef;
        if (contextContent.isNotEmpty && contextContent != 'Genel √∂ƒürenci sorusu') {
          sourceRef = contextContent.length > 100 
              ? '${contextContent.substring(0, 100)}...'
              : contextContent;
        }
        
        return AIAnswer(
          question: userQuery,
          answer: responseText.trim(),
          sourceReference: sourceRef,
          timestamp: DateTime.now(),
          isRelevant: true,
        );
        
      } catch (e) {
        debugPrint('‚ö†Ô∏è  Attempt $attempt failed: $e');
        _lastError = 'Attempt $attempt: $e';
        
        if (attempt == maxRetries) {
          debugPrint('‚ùå All retry attempts exhausted');
          
          // Return user-friendly error
          return AIAnswer(
            question: userQuery,
            answer: _buildFallbackResponse(language, e.toString()),
            sourceReference: null,
            timestamp: DateTime.now(),
            isRelevant: false,
          );
        }
        
        // Exponential backoff
        await Future.delayed(Duration(milliseconds: 500 * attempt));
      }
    }
    
    // Should never reach here
    throw Exception('Unexpected error in answerQuestion');
  }

  /// Build comprehensive prompt for question answering
  String _buildQuestionPrompt(String question, String context, String language) {
    final buffer = StringBuffer();
    
    // Add user profile context if available
    if (_userProfile != null && !_userProfile!.isGuest) {
      buffer.writeln('√ñƒûRENCƒ∞ PROFƒ∞Lƒ∞:');
      buffer.writeln(_userProfile!.buildAIContext());
      buffer.writeln();
      
      // Add grade-specific instructions
      if (_userProfile!.gradeLevel != null) {
        buffer.writeln('√ñNEMLƒ∞: Bu √∂ƒürenci ${_userProfile!.formattedGrade ?? _userProfile!.gradeLevel} seviyesinde.');
        buffer.writeln('A√ßƒ±klamalarƒ±nƒ± ve √∂rneklerini bu sƒ±nƒ±f seviyesine g√∂re uyarla.');
        buffer.writeln();
      }
    }
    
    // Add context if available
    if (context.isNotEmpty && context != 'Genel √∂ƒürenci sorusu') {
      buffer.writeln('BAƒûLAM (Ders Materyalinden):');
      buffer.writeln(context);
      buffer.writeln();
    }
    
    // Add student question
    buffer.writeln('√ñƒûRENCƒ∞ SORUSU:');
    buffer.writeln(question);
    buffer.writeln();
    
    // Add instructions
    buffer.writeln('G√ñREV:');
    buffer.writeln('Bu soruyu detaylƒ± ama anla≈üƒ±lƒ±r bir ≈üekilde yanƒ±tla.');
    
    if (_userProfile != null && _userProfile!.gradeLevel != null) {
      buffer.writeln('√ñƒürenci ${_userProfile!.formattedGrade ?? _userProfile!.gradeLevel} seviyesinde olduƒüundan, a√ßƒ±klamalarƒ±nƒ± buna g√∂re yap.');
    } else {
      buffer.writeln('√ñƒürenci lise seviyesinde, bu y√ºzden basit ve net a√ßƒ±kla.');
    }
    
    if (context.isNotEmpty && context != 'Genel √∂ƒürenci sorusu') {
      buffer.writeln('Yukarƒ±daki baƒülamƒ± kullanarak yanƒ±t ver ve √∂ƒürenciyi kaynak materyale y√∂nlendir.');
    }
    
    if (_userProfile != null && _userProfile!.school != null) {
      buffer.writeln('√ñƒürenci ${_userProfile!.school} okulunda okuyor. Gerekirse b√∂lgesel veya okula √∂zg√º referanslar kullanabilirsin.');
    }
    
    return buffer.toString();
  }

  /// Build user-friendly fallback response for errors
  String _buildFallbackResponse(String language, String errorDetails) {
    debugPrint('üîç Error details: $errorDetails');
    
    final lowerError = errorDetails.toLowerCase();
    
    // Check for specific error types
    if (lowerError.contains('api key') || lowerError.contains('401') || lowerError.contains('403') || lowerError.contains('unauthorized')) {
      return language == 'tr'
          ? 'API anahtarƒ± ge√ßersiz veya s√ºresi dolmu≈ü. L√ºtfen y√∂neticinize ba≈üvurun.'
          : 'API key is invalid or expired. Please contact your administrator.';
    }
    
    if (lowerError.contains('quota') || lowerError.contains('429') || lowerError.contains('rate limit')) {
      return language == 'tr'
          ? 'AI servisinin kullanƒ±m limiti a≈üƒ±ldƒ±. L√ºtfen birka√ß dakika sonra tekrar deneyin.'
          : 'AI service quota exceeded. Please try again in a few minutes.';
    }
    
    if (lowerError.contains('network') || lowerError.contains('connection') || lowerError.contains('timeout')) {
      return language == 'tr'
          ? 'ƒ∞nternet baƒülantƒ±sƒ± sorunu var gibi g√∂r√ºn√ºyor. L√ºtfen baƒülantƒ±nƒ±zƒ± kontrol edin ve tekrar deneyin.'
          : 'There seems to be a network connectivity issue. Please check your connection and try again.';
    }
    
    if (lowerError.contains('model') || lowerError.contains('gpt') || lowerError.contains('404')) {
      return language == 'tr'
          ? 'AI model eri≈üim sorunu var. L√ºtfen API anahtarƒ±nƒ±zƒ±n ge√ßerli olduƒüundan emin olun.'
          : 'Issue accessing AI model. Please ensure your API key is valid.';
    }
    
    // Generic error
    return language == 'tr'
        ? '√úzg√ºn√ºm, ≈üu anda yanƒ±t veremiyorum. Sorunuzu biraz daha farklƒ± bir ≈üekilde sormayƒ± dener misiniz? Veya l√ºtfen daha sonra tekrar deneyin.'
        : 'Sorry, I cannot respond right now. Could you try rephrasing your question? Or please try again later.';
  }

  /// Clear conversation history (for new chat sessions)
  void clearHistory() {
    _conversationHistory.clear();
    debugPrint('üßπ Conversation history cleared');
  }

  /// Get last error for debugging
  String? getLastError() => _lastError;

  /// Check if service is ready
  bool get isInitialized => _isInitialized;

  /// Get conversation history length
  int get historyLength => _conversationHistory.length;

  /// Generate summary from context content
  Future<AISummary> generateSummary(
    String contextContent, {
    String language = 'tr',
  }) async {
    if (!_isInitialized) {
      throw Exception('OpenAI LLM Service not initialized. Call initialize() first.');
    }

    if (contextContent.trim().isEmpty) {
      throw Exception('Context content cannot be empty');
    }

    debugPrint('üìù Generating summary from context...');

    try {
      final prompt = _buildSummaryPrompt(contextContent, language);

      final chatCompletion = await OpenAI.instance.chat.create(
        model: 'gpt-4o-mini',
        messages: [
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.system,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                'Sen bir √∂ƒüretmen asistanƒ±sƒ±n. Verilen i√ßeriƒüi √∂zetleyip √∂ƒürenciler i√ßin anla≈üƒ±lƒ±r hale getiriyorsun.',
              ),
            ],
          ),
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(prompt),
            ],
          ),
        ],
        temperature: 0.7,
        maxTokens: 1024,
      );

      final summary = chatCompletion.choices.first.message.content?.first.text;
      
      if (summary == null || summary.trim().isEmpty) {
        throw Exception('Empty summary from OpenAI');
      }

      debugPrint('‚úÖ Summary generated (${summary.length} chars)');
      
      // Extract key points (simple implementation - split by sentences)
      final sentences = summary.trim().split(RegExp(r'[.!?]\s+'));
      final keyPoints = sentences.take(5).where((s) => s.trim().isNotEmpty).toList();
      
      return AISummary(
        keyPoints: keyPoints,
        fullSummary: summary.trim(),
        timestamp: DateTime.now(),
        sourceContext: contextContent,
      );
    } catch (e) {
      debugPrint('‚ùå Error generating summary: $e');
      throw Exception('Failed to generate summary: $e');
    }
  }

  /// Create quiz item from topic
  Future<AIQuizItem> createQuizItem(
    String topic,
    QuizDifficulty difficulty, {
    String language = 'tr',
  }) async {
    if (!_isInitialized) {
      throw Exception('OpenAI LLM Service not initialized. Call initialize() first.');
    }

    if (topic.trim().isEmpty) {
      throw Exception('Topic cannot be empty');
    }

    debugPrint('üìù Creating quiz item for topic: $topic (difficulty: $difficulty)');

    try {
      final prompt = _buildQuizPrompt(topic, difficulty, language);

      final chatCompletion = await OpenAI.instance.chat.create(
        model: 'gpt-4o-mini',
        messages: [
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.system,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                'Sen bir √∂ƒüretmen asistanƒ±sƒ±n. √ñƒürenciler i√ßin √ßoktan se√ßmeli sorular olu≈üturuyorsun. Yanƒ±tƒ±nƒ± JSON formatƒ±nda ver: {"question": "soru metni", "options": ["A) se√ßenek1", "B) se√ßenek2", "C) se√ßenek3", "D) se√ßenek4"], "correctAnswerIndex": 0, "explanation": "a√ßƒ±klama"}',
              ),
            ],
          ),
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(prompt),
            ],
          ),
        ],
        temperature: 0.8,
        maxTokens: 1024,
      );

      final response = chatCompletion.choices.first.message.content?.first.text;
      
      if (response == null || response.trim().isEmpty) {
        throw Exception('Empty response from OpenAI');
      }

      // Try to parse JSON response
      try {
        // Extract JSON from response (might have markdown code blocks)
        String jsonStr = response.trim();
        if (jsonStr.startsWith('```json')) {
          jsonStr = jsonStr.substring(7);
        }
        if (jsonStr.startsWith('```')) {
          jsonStr = jsonStr.substring(3);
        }
        if (jsonStr.endsWith('```')) {
          jsonStr = jsonStr.substring(0, jsonStr.length - 3);
        }
        jsonStr = jsonStr.trim();

        // Simple JSON parsing (for basic structure)
        // In production, use proper JSON parsing
        final questionMatch = RegExp(r'"question"\s*:\s*"([^"]+)"').firstMatch(jsonStr);
        final optionsMatch = RegExp(r'"options"\s*:\s*\[(.*?)\]', dotAll: true).firstMatch(jsonStr);
        final correctIndexMatch = RegExp(r'"correctAnswerIndex"\s*:\s*(\d+)').firstMatch(jsonStr);
        final explanationMatch = RegExp(r'"explanation"\s*:\s*"([^"]+)"').firstMatch(jsonStr);

        if (questionMatch == null || optionsMatch == null || correctIndexMatch == null) {
          throw Exception('Invalid JSON format in response');
        }

        final question = questionMatch.group(1) ?? topic;
        final optionsStr = optionsMatch.group(1) ?? '';
        final options = RegExp(r'"([^"]+)"')
            .allMatches(optionsStr)
            .map((m) => m.group(1) ?? '')
            .where((s) => s.isNotEmpty)
            .toList();
        
        if (options.length < 4) {
          // Fallback: create default options
          options.clear();
          options.addAll([
            'A) Se√ßenek 1',
            'B) Se√ßenek 2',
            'C) Se√ßenek 3',
            'D) Se√ßenek 4',
          ]);
        }

        final correctIndex = int.tryParse(correctIndexMatch.group(1) ?? '0') ?? 0;
        final explanation = explanationMatch?.group(1) ?? 'Doƒüru cevap a√ßƒ±klamasƒ±';

        final quizItem = AIQuizItem(
          question: question,
          options: options,
          correctAnswerIndex: correctIndex.clamp(0, options.length - 1),
          explanation: explanation,
          topic: topic,
          difficulty: difficulty,
          timestamp: DateTime.now(),
        );

        debugPrint('‚úÖ Quiz item created');
        return quizItem;
      } catch (e) {
        debugPrint('‚ö†Ô∏è Failed to parse JSON, creating fallback quiz: $e');
        // Fallback: create a simple quiz item
        return AIQuizItem(
          question: '$topic hakkƒ±nda bir soru',
          options: [
            'A) Se√ßenek 1',
            'B) Se√ßenek 2',
            'C) Se√ßenek 3',
            'D) Se√ßenek 4',
          ],
          correctAnswerIndex: 0,
          explanation: 'Bu konu hakkƒ±nda daha fazla √ßalƒ±≈ümanƒ±z gerekiyor.',
          topic: topic,
          difficulty: difficulty,
          timestamp: DateTime.now(),
        );
      }
    } catch (e) {
      debugPrint('‚ùå Error creating quiz item: $e');
      throw Exception('Failed to create quiz item: $e');
    }
  }

  /// Build prompt for summary generation
  String _buildSummaryPrompt(String context, String language) {
    final buffer = StringBuffer();
    
    buffer.writeln('A≈üaƒüƒ±daki i√ßeriƒüi √∂zetle ve √∂ƒürenciler i√ßin anla≈üƒ±lƒ±r hale getir:');
    buffer.writeln();
    buffer.writeln(context);
    buffer.writeln();
    buffer.writeln('√ñzet T√ºrk√ße olmalƒ± ve anahtar noktalarƒ± i√ßermelidir.');
    
    return buffer.toString();
  }

  /// Build prompt for quiz generation
  String _buildQuizPrompt(String topic, QuizDifficulty difficulty, String language) {
    final buffer = StringBuffer();
    
    final difficultyText = {
      QuizDifficulty.easy: 'kolay',
      QuizDifficulty.medium: 'orta',
      QuizDifficulty.hard: 'zor',
      QuizDifficulty.expert: 'uzman',
    }[difficulty] ?? 'orta';
    
    buffer.writeln('Konu: $topic');
    buffer.writeln('Zorluk: $difficultyText');
    buffer.writeln();
    buffer.writeln('Bu konu hakkƒ±nda √ßoktan se√ßmeli bir soru olu≈ütur. Soru T√ºrk√ße olmalƒ± ve 4 se√ßenek i√ßermelidir.');
    
    return buffer.toString();
  }

  /// Dispose resources
  void dispose() {
    _conversationHistory.clear();
    _isInitialized = false;
    debugPrint('üóëÔ∏è  OpenAI LLM Service disposed');
  }
}
